%\setchapterpreamble[uc][0.8\textwidth]{%
%	\dictum[George Bernard Shaw]{%
%		``It is the mark of a truly intelligent person to be moved by statistics.''}\vskip20em}
	
%\setchapterpreamble[uc][0.8\textwidth]{%
%			\dictum[George Bernard Shaw]{%
%				``Science never solves a problem without creating ten more.''}\vskip20em}

%\setchapterpreamble[uc][0.8\textwidth]{%
%	\dictum[Han Solo]{%
%		``She may not look like much, but she's got it where it counts.''}\vskip20em}			
	

\setchapterpreamble[uc][0.8\textwidth]{%
	\dictum[Frederick Mosteller]{%
		``It is easy to lie with statistics, it is easier to lie without them.''}\vskip20em}		

	
\chapter{Introduction}
\label{chap:intro}
\newpage
%------------------------------------------------------------------------------------------------%
% ---------------------------- History and state of the art------------------------------------- %
\section{Short history of forest inventory}
\label{sec:intro:hist_soa}

% --- first part ---

Riding and walking through the forests, gaining a representative impression of the forest's state and looking for forest stands to be harvested - that pictures the way how the first forest inventories were conducted, dating back to the 14th and 15th century \citep{zoehrer1980}. Whereas these inspections already constituted a response to increasing wood shortages, the first reference to sustainable forest management in literature is only found two centuries later in the book \textit{Silviculatura Oeconomica} written by \citet{carlowitz1713}, who suggested concepts that besides reforestation mostly targeted at a 'continuous and sustainable' use of wood. This basic concept of sustainability requires frequently updated and reliable information about the forested areas. It has been mainly for this reason why forest inventory methods have evolved over the years, particularly over the last decades, and today look quite different from those of the late middle ages.\par

While the first use of sample plots to gather representative information about the state and development of forests date back to \citet{hartig1795}, major advancements of sample-based inventories came up at the beginning of the 20th century together with the development of statistical sampling methods \citep{schreuder1993}. In North America, the first sample-based inventories (so-called \textit{timber cruises}) were conducted around 1930 \citep{kangas2006}. The surveys were initially performed by visual assessments and later by a full census of all trees along systematically arranged lines. The idea of these so-called \textit{strip-sampling} inventories was to gather information only for a small percentage of the forest, and this information was then subsequently extrapolated to the entire forest area. In addition, the surveyed strips were also used to provide forest attribute maps. These strip sampling techniques were further developed by \citet{goodspeed1934} and \citet{langballe1938} who both proposed to collect information only within sample plots aligned with the strip lines (line-plot sampling) in substitution for a complete census within the stripes as a means to reduce costs and to make the cruises more efficient.\par 

In addition to improving the efficiency of sampling techniques, it also became of high importance to reliably quantify the estimation errors associated to estimated forest attributes \citep{kangas2006}. Solutions were developed in two mathematical frameworks of inference that rely on either randomization of the sampling process or sampling from an underlying stochastic process and are today known as the \textit{design-based} and \textit{model-dependent} approach. Randomization of the sample plot locations in order to allow for a valid estimate of the sampling error was first recommended by \citet{hasel1938}. A substantial advancement in design-based survey sampling constituted the concept of unequal probability sampling by \citet{hansen1943}, who showed that using inclusion probabilities proportional to the value of the target attribute (so-called \textit{probability proportional to size} or \textit{PPS} sampling) could substantially increase estimation precision. An unbiased estimator for unequal probability sampling was then contributed by \citet{horvitz1952}. The concept of \textit{PPS} sampling is implemented in most of today's forest inventories by the use of concentric sample plots. A method which perfectly implements PPS sampling is the angle-count sampling (ACS) technique introduced by Bitterlich in 1947 \citep{bitterlich1984}, and it was \citet{grosenbaugh1958} who related ACS to the probabilistic sampling theory. A further important contribution by \citet{mandallaz1991} was the reformulation of the design-based estimation framework, in particular the Horwitz-Thompson estimator, within the \textit{infinite population approach}. This approach provided a much better definition of the underlying population for forest inventories compared to design-based survey methods for finite populations as applied in official statistics \citep[e.g.,][]{sarndal2003}.\par

The huge advancements in the conduction of national forest inventories in the Nordic countries around 1920 considerably contributed to the development of estimators in the model-dependent framework, since these inventories used the concept of systematic strip sampling. Especially the variance estimators for systematic sampling by Mat\'{e}rn (1947, 1960) were used to quantify the estimation precisions \citep{kangas2006}. Even while Mat\'{e}rns variance estimators relied on modeling spatial trends, it was \citet{houllier1987} and then \citet{mandallaz1993} who first applied geostatistical kriging techniques in the field of forest inventory.\par

% part 1:
A groundbreaking invention in sampling methodology that came up in the 1930s and has decisively shaped today's forest inventories was double-sampling. The major difference to the existing methods was that in order to produce estimates, double-sampling allowed to include information derived from two samples (so-called \textit{phases}) of different sampling frequencies. This was of particular advantage in cases where gathering the target variable of interest was considerably cost-intensive, and less precise but cheap information related to the target variable (so-called \textit{auxiliary information}) was available for the estimation domain in high quantity. The collection of the cost-intensive information could thus be restricted to a small sample, and estimation precision could then be boosted by combining this information with a large sample of explanatory variables derived from the auxiliary information. First studies that introduced this technique were those of \citet{neyman1938}, who applied double-sampling for stratification in the field of census statistics, and \citet{watson1937} who used double-sampling for regression to estimate the leaf area in field crops. It did not take a long time until double-sampling was applied to forest inventories. According to \citet{kangas2006}, the first study was conducted in the USA by \citet{bickford1952, bickford1953} who used double-sampling to estimate total timber volume by combining classification of forest area based on aerial photography with terrestrial field measurements. The use of aerial images in forestry had its origin even 40 years before the first applications of double-sampling. The earliest developments date back to around 1910, and the first device for an automated evaluation of aerial images was developed by Karl Hugershoff at the forest institute in Tharandt, Germany in 1918 \citep{prager1961}. In Canada and the USA, aerial photographs were operationally used since 1920 to support the allocation of field inventories and improve forest attribute maps, thereby increasing the efficiency of forest inventories \citep{langballe1938}. In the following years, considerable efforts were invested in methods and guidelines to derive numerous forest attributes via aerial photo interpretation \citep[e.g.,][]{hildebrandt1996}, and \citet{zoehrer1980} already referred to the use of aerial photography as an integral part of a forest inventory. The introduction of double-sampling to forest inventories considerably extended the area of application of aerial photo interpretation with respect to including the derived information in the estimators. E.g., in the early stages of the planning process for the first National Forest Inventory in Switzerland, \citet{schmid1970} already suggested to use a double-sampling procedure where numerous attributes on sample plot level are derived by interpretation of aerial images in a large sample, and a smaller subsample is then terrestrially measured by field crews. This concept was then indeed implemented in the second Swiss NFI and has since been an integral part of the estimation procedures \citep{brassel2001}. Whereas the visual interpretation of aerial images was already much cheaper than conducting field measurements, the actual breakthrough came with the possibility to derive explanatory variables automatically, accompanied by new promising remote sensing sources such as satellite data \citep{hildebrandt1987}.\par

% part 2:
With respect to the estimation of timber volume, one of today's best investigated and most commonly used auxiliary information incorporated in double-sampling estimation procedures is derived from airborne laser scanning (ALS) data. First studies exploring the capabilities of this technique for forestry applications date back to the 1980s. \citet{nelson1984} conducted one of the first studies and found that ALS was well suited to access the vertical structure of the forest canopy and tree heights. Two years later, \citet{maclean1986} demonstrated that predictor variables derived from ALS can be used to generate estimates of timber volume with high prediction accuracy. The reproducibility of such estimates under varying ALS acquisition modes as a prerequisite for operational use was addressed by \citet{nelson1988} and has been confirmed by numerous, more recent studies. It were again the Nordic countries that early started working on the integration of ALS data into existing forest inventories in the 1990s. The first tests were conducted in Norway by \citet{naesset1997a, naesset1997b} and comprised the estimation of the mean canopy height and timber volume on forest stand level. \citet{naesset2002} then introduced the so-called area-based approach where timber volume estimates of a forest stand are generated by averaging individual grid cell estimates within the area of interest. Since these early studies, the application of ALS-assisted forest inventories has become a common practice in the Nordic countries \citep{maltamo2014}, and their conduction has been provided by numerous commercial enterprises. Another remote sensing source that has a long tradition in supporting forest inventories is satellite imagery. Opposed to aerial photography and ALS acquisitions, satellite data often cover very large areas which consequently makes them well suited for large-scale applications. Their steadily increasing spatial and spectral resolution has recently allowed to extent their area of application to tree species classification \citep[e.g.,][]{stoffels2012}. A comprehensive overview about the past and recent developments as well as opportunities of different remote sensing sources in forestry has lately been given by \citet{white2016}. An important conclusion of their review was that for future applications in forest inventories, the major potential lies in the combination of different remote sensing sources. A study that impressively demonstrated the potential of this approach is \citet{matasci2018} who recently combined ALS-derived sample plot metrics with wall-to-wall Landsat satellite data to compute prediction maps of various forest attributes over the entire boreal forest of Canada.\par

%% part 3:
The work on estimation techniques that combine terrestrially gathered inventory data and auxiliary information from various sources has been shaping forest inventories for the last decades. Since its introduction to forestry in 1952, multi-phase sampling methods have been extensively described in forest inventory literature \citep[e.g.,][]{gregoire2007, kohl2006, kangas2006, schreuder1993, mandallaz2008, saborowski2010, vonLuepke2012, mandallaz2013c} and numerous studies have shown their efficiency in terms of cost reduction and increase in estimation precision \citep[e.g.,][]{ bockmann1998, vonluepke2013, mandallaz2013b, massey2015_thesis}. Additionally supported by the ongoing improvements in remote sensing techniques and data availability, future forest inventories will continue to increasingly integrate remote sensing data as auxiliary information \citep{kangas2018}. One of the current challenges has been to apply multi-phase sampling techniques also to forest management units where the number of terrestrial inventory information is rare or even absent. Producing reliable estimates on these spatial scales is referred to as \textit{small area estimation}, and respective estimators have been developed and successfully applied in both the model-dependent \citep{naesset1997b, breidenbach2016} and the design-based framework \citep{mandallaz2013a, mandallaz2013b, mandallaz2013c}. It has recently been of particular interest to apply these small area estimation methods to national forest inventory data that are per se characterised by low sampling densities and have yet not provided sufficient estimation precision below the national scale. Applications of small area estimation procedures to NFI data in Norway \citep{breidenbach2012} and Switzerland \citep{magnussen2014a} have already provided examples where acceptable estimation precisions were achieved on the spatial level of municipalities and forest districts. However, the integration of small area estimation procedures in operational forest inventories has still been rare and is subject to current efforts.

%
% ****
% part 3:
% - 
% - special application of small area estimation
% ****
% - end with: * A conclusion from recent developments is that future forest planning methods will increasingly integrate information of auxiliary data such as remote sensing and geo data (kangas 2018)
%             * The task is to develop and evaluate mp metods with regards to their operational use in large scale forest inventories  --> currently: "from small-scale case studies to large-scale operational application"
%






\newpage
%------------------------------------------------------------------------------------------------%
% ---------------------------------- Goals ----------------------------------------------------- %
\section{Thesis objective and structure}
\label{sec:intro:obj_and_struct}


% focus on strategy:
% - evaluate the tested methods with respect to their operational use, i.e. become an integral part of future forest inventories.
% Criteria are:
%      -> operationally applicable over large forest areas (country, - state-wide)
%      -> transferability to areas of application
%      -> effort to frequently produce estimates of numerous forest attributes 
%      -> provide reliable accuracy specifications
%
% -> this also included to add / develop / suggest techniques to process the auxiliary data
% -> particularly including dealing with quality restrictions in the auxiliary data 

% Important criteria were considered to be:
%
%- the magnitude of estimation precision on the respective management level
%- the ability of the small area estimators to
%   a) operationally applicable over large forest areas (country, - state-wide)
%   b) be frequently repeated
%   c) be transferred / applicable to numerous forest attributes under comparable low effort
%   d) provide reliable specification of their estimation errors (uncertainties / precisions)
%- the identification of suitable auxiliary information, especially remote sensing data, with respect to their predictive power and their future availability


National Forest Inventories (NFIs) have a long tradition of providing reliable and accurate information of the state and the development of forests on the national level. However, the operational use of NFI data on smaller spatial levels has often been hampered by insufficient estimation precision due to low sample sizes below the national scale. The objective of this thesis was to contribute procedures to increase the value of National Forest Inventory data for forest authorities by extending their applicability also to estimation on small-scale forest management levels. The two methods that were closer investigated in this thesis all rely on combining the terrestrially gathered inventory data with remote sensing data that are available over the entire inventory area. It was of particular interest to evaluate these so-called \textit{small area estimation procedures} with respect to their suitability to be integrated in future operational NFIs. Thus, important criteria to evaluate the tested small area estimation procedures were the following: (1) The estimation method has to provide means to reliably quantify the precision of the estimates. (2) The magnitude of estimation precision on the respective management level has to satisfy the needs of forest practice. (3) The procedure has to be frequently applicable over large areas (national or regional level) and also be transferable to numerous forest attributes with comparatively low effort. This also particularly imposes high requirements on the software used to produce the estimates with respect to robustness against special cases and errors in data, handling of diverse inventory scenarios, and reproducibility of the estimation results. (4) The remote sensing information identified as valuable for the estimation purpose should have the perspective to be frequently acquired in the future. With respect to these criteria, two methods were investigated in separate studies: The first study \hyperref[sec:study1]{(study 1)} constitutes the main part of this thesis and explored the capabilities and performances of design-based multi-phase regression estimators in the service of small area estimation. The second study \hyperref[sec:study2]{(study 2)} concentrated on the first criterion and investigated a new approach for evaluating the estimation accuracies of forest attribute maps, which are considered to be a special case of small area estimation. The following subsections will give a more detailed introduction to each of the studies.


% --------------------------------- %
% --------------------------------- %
\subsection{Study 1: Design-based small area estimation}
\label{sec:study1}

% ############################################################
% ## ===== general information on study 1 (RLP SAEs) ====== ##

In recent years, methods for the family of model-assisted design-based estimators developed under the infinite population approach have considerably been contributed to by the works of \citet{mandallaz1991, mandallaz2008, mandallaz2013a, mandallaz2013c} and \citet{mandallaz2013b}. The potential of these estimators to be integrated in existing National Forest Inventories for \textit{global} estimation has recently been demonstrated by \citet{massey2015_thesis}. Study 1 continued this work by exploring the suitability of these estimators for the special case of small area estimation. With respect to the thesis objective, the particular aim of the study was to test the estimators as the integral part of a double-sampling estimation procedure for the German National Forest Inventory (German NFI). Opposed to similar small area estimation studies in Norway \citep{breidenbach2012} and Switzerland \citep{magnussen2014a, steinmann2013}, no such study had yet been conducted in Germany. The design-based double-sampling estimators were considered to be well suited for the study objective since they are explicitly formulated for cluster sampling designs such as applied in the German NFI, which has not yet been the case for frequently used model-dependent estimators. In order to evaluate the performance of the estimators with respect to their future large-scale operational use, the procedure was implemented and applied over the entire forest area of the German federal state Rhineland-Palatinate (appr. 8400 km$^2$). This finally led to the calculation and evaluation of standing timber volume estimates and their associated estimation precisions on two forest district levels that in total comprised 45 and 405 management units respectively. The work on the study was divided into 3 major tasks which each addressed one of the previously mentioned criteria for future operational application. The work and results of these tasks are subsequently presented in chapter \ref{chap:rpack}, chapter \ref{chap:regmod} and chapter \ref{chap:sae}, and the following sections will give an introduction and some additional background information to each of these chapters.


% ---------------------- %
% ---------------------- %
\subsubsection{Task 1: Software implementation} % Chapter 2

% ----------------------------------------------
% # --- Chapter 2: Software implementation --- #

Task 1 addressed the need of a robust and flexible software implementation of the design-based regression estimators that could handle very large data sets and process numerous small area estimations at once. Whereas several of the estimators suggested by Mandallaz had been applied in simulations and real-world case studies \citep{mandallaz2013a, mandallaz2013b, mandallaz2013c, massey2014a, massey2015a, massey2015b}, there had yet not been an unified and consistent implementation of the estimators in the same software environment. The work on this study was thus taken as an opportunity to implement the full range of these regression estimators in the statistical software \proglang{R} \citep{R}. The implementation procedure comprised three steps in general: First, a comprehensive review of the regression estimators published by Mandallaz; second, the completion of yet missing estimators for three-phase small area estimation; and third, the actual implementation of the estimators in \proglang{R}. The latter seemed to be the software of choice, as it currently constitutes one of the most intensively used statistical software and also provides interfaces to data base systems in which inventory and geodata are commonly stored. A review of existing software for multi-stage and multi-phase estimation revealed that in comparison to official statistics, applications particularly suited for forest inventories have been rare. Exceptions are the \proglang{R} package \pkg{JoSAE} by \citet{josae2015} and the \pkg{maSAE} package by \citet{cullmann2016}. However, a more comprehensive software package covering a larger variety of sample designs and estimators - particularly in the design-based infinite population framework - had not yet been available. In order to address this lack between availability and recent interest in such methods, the software package has also been made freely available (\proglang{R} package \pkg{forestinventory}) and can be installed from the CRAN server (\url{https://CRAN.R-project.org/package=forestinventory}). Chapter \ref{chap:rpack} describes the implementation and the application of the two-phase and three-phase estimators in \proglang{R} and provides a comprehensive review of the design-based regression estimators for global and small area estimation described in \citet{mandallaz2008, mandallaz2013a, mandallaz2013c} and \citet{mandallaz2013b}. The availability of the software package in combination with its comprehensive documentation also had the objective to support the transparency and the reproducibility of the methods applied in this thesis.


%   - provides a review of all design-based estimators for global and small area estimation published by Mandallaz
%   - describes the implementation of the 2p/3p estimators in the statistical software R
%   - provides consistent framework to process large amount of data (plausibility checks, data intergrity, ...) 
%      objectives / requirements on software:
%      - provides calculation and comparison of the estimators based on the same input dataset
%      - provides summarized, standardized outputs for further analysis and visualization
%      - addresses the lack of available software for design-based estimations in forest inventories
%      - mention documentation: R-help, github, vignette
%      - end with: The availability of the software package in combination with its comprehensive documentation als had the objective to support the transparency and the reproducibility of the methods applied in this thesis.

%% for Discussion:
%   - development of a robust and flexible software application which allowed for the calculation of a comprehensive set of small area regression estimators
%   - the software is - at the moment - the most extensive open-source software for design-based estimation for forestry applications. The interest and need of such software was also indicated by
%     xxx download between the first and second release (maybe put this in Synthesis --> turned out that this software was needed and has widely been recognized ... / and feedback reveived from researchers as well as practioners).


% ---------------------- %
% ---------------------- %
\subsubsection{Task 2: Processing of auxiliary data and model building} % Chapter 3

%--------------------------------
% # --- Chapter 3: Modeling --- #

Task 2 had the objective to identify a suitable ordinary least square (OLS) regression model to be integrated in the small area regression estimators. In order to apply the regression estimators over the entire area of RLP, the regression model had to allow for predicting the standing timber volume of a German NFI sample plot at any location within the federal state forest area. This consequently imposed the requirement on the auxiliary data to be available over the entire federal state area. With respect to a future operational application of the estimation procedure, the auxiliary data also had to meet the requirement of a continued acquisition in the future. In this regard, two remote sensing data products were identified to provide explanatory variables for timber volume modeling. These data were an airborne laser scanning (ALS) data set and a satellite-based tree species classification map. The country-wide airborne laser scanning (ALS) data was acquired over several consecutive years and subsequently characterized by severe quality variations as well as time lags of up to 10 years between the ALS acquisitions and the terrestrial survey date. Consequently, an objective was to specifically address techniques to improve the performance of ordinary least square regression models under such restricting conditions. The combination of ALS with tree species map information for timber volume modeling has often been stated as some of the most promising but often missing and thus not well investigated information \citep{koch2010, white2016}. In this context, one yet existing gap of knowledge also concerned the effect of species misclassifications, i.e., errors in the explanatory variables, on the precision of the regression model. This question was addressed by proposing a calibration technique for removing a potential bias in the regression coefficients caused by such misclassifications. An additional challenge that further increased the complexity of the model selection procedure was the identification of optimal extraction areas (\textit{supports}) for the explanatory variables under varying plot sizes due to the angle count sampling technique applied in the German NFI. The overall question of the study was whether the frame of an OLS regression model provided enough flexibility to cope with the mentioned challenges in the data set. Besides these modeling-specific aspects, the work on this study comprised the integration and storage of both the terrestrial NFI data and the remote sensing data in a PostgreSQL database using a PostGIS extension. The latter allowed for a georelational storage and query of both data sources and provided fast computation of explanatory variables for large data sets.

% - some background info on data handling: - PostgreSQL-Server, PostGIS extension
% - Modeling the 'FI timber volume' based on available auxiliary data
% - basically constitutes the 'data preparation' for the sae-estimations 
% - consistent storage which provides data integrity, relations and flexbility in terms of queries ...
% - sanitize existing data to match requirements of estimators (geo-relational propoerties ...)
% - in this study only modeling on the plot level, an extended evaluation of the model on the cluster level is introduced in chapter 4
% - also addressing the question whether the frame of OLS regression models - which the estimators are restricted to if the g-weight variance is desired - provides enough flexibility to model the data

% ---------------------- %
% ---------------------- %
\subsubsection{Task 3: Small area estimation} % Chapter 4

% -------------------------------------
% # --- Chapter 4: SAE estimation --- #

Task 3 comprised the actual application of the regression estimators for small area estimation and built upon a synthesis of the methods developed in task 1 and 2. The aim of this study was to investigate the estimation precisions that can be achieved for timber volume estimation on the small scale forest management units by the proposed design-based small area estimation procedure. This first comprised an extension of the existing NFI sample grid in the study area (RLP) to a double-sampling cluster design, and the derivation of the explanatory variables used in the regression model (task 2) at each sample location. Three types of design-based small area regression estimators were then applied to derive point and variance estimates of mean standing timber volume on two forest management levels over the entire federal state area, comprising 45 \textit{Forst{\"a}mter} and 405 \textit{Forstreviere} (i.e., small area units) respectively. The small area estimators considered were the \textit{pseudo-small}, \textit{extended pseudo-synthetic} and the \textit{pseudo-synthetic} design-based small area estimator for cluster sampling suggested by \citet{mandallaz2013a, mandallaz2013b}. An evaluation of the error distribution of these estimators on both small area levels served as a first means to quantify the estimation precisions achievable under each estimator. The estimation results of the multi-phase estimators were also compared to the one-phase estimator for cluster sampling that exclusively uses the terrestrially observed data available within a small area unit in order to specify the gain in efficiency provided by the suggested double-sampling procedure. The results of our evaluations were subsequently used to discuss the potential of the suggested design-based small area regression estimators for future operational applications.

%\newpage
% --------------------------------- %
% --------------------------------- %
\subsection{Study 2: Mapping} % Chapter 5
\label{sec:study2}

% ###########################################################
% ## ===== general information on study 2 (Mapping) ====== ##

Forest attribute maps provide an area-wide overview of important information such as development stages, tree species or growing conditions and have thus always been of high interest for forest practitioners. For a long time, such maps were exclusively produced by hand and required expensive field visits and visual inspection of aerial photography. This amount of work also hampered a frequent updating of the maps. However, the production of maps (\textit{mapping}) covering large areas has lately been substantially supported by the availability of exhaustive remote sensing data in combination with modeling techniques \citep{brosofske2014}. Especially maps of predicted forest attributes in high resolution are considered to support the spatially precise allocation of management operations such as harvesting. An example is the use of rasterized timber volume prediction maps for the optimal allocation of cable roads in the frame of harvesting in steep slope mountainous terrains \citep{bont2012, bont2015}.\par

Despite the advantages of providing such high-resolution prediction maps, one should have in mind that the predictions are often made for considerably small spatial units (map pixels). In most cases, the map pixels match the extent of an inventory sample plot on which the prediction model has been calibrated. One can thus interpret mapping as an extreme case of \textit{small area estimation}. Design-based double-sampling estimators for small area estimation (study 1) provide closed-form variance formulas that allow to quantify the estimation precision for every small area unit individually by its estimation error and confidence interval. However, these concepts of quantifying the uncertainty cannot be transferred to mapping approaches in the particular case of a small area unit (i.e., map pixel) corresponding to the size of a sample plot. It is thus necessary that similar efforts for model building are invested in methods that reliably quantify the resulting map accuracies. A common way to characterize the map accuracy is to use criteria such as the coefficient of determination (R$^2$) or cross-validated root mean square error (RMSE), which rather address the overall prediction performance than the accuracy of individual predictions. For this reason, the specification of confidence intervals on pixel level has been stated as an important contribution to map accuracy assessment \citep{mcroberts2010a}.\par

In case of continuous response variables such as standing timber volume, the application of linear regression models allows for providing a confidence region for each prediction (i.e., pixel) based on the \textit{prediction interval} \citep[pp.136--139]{fahrmeir2013}. The objective of the study presented in Chapter \ref{chap:regmod} was to investigate an alternative approach of deriving pixel-wise confidence intervals by applying well-known concepts of accuracy assessment for categorical classification results \citep{congalton2008}. The core of the suggested approach was the definition of intervals within the range of terrestrial data and their respective model predictions, and subsequently calculate the \textit{user's accuracy} for each of those intervals. The calculated users' accuracies can then be regarded as the confidence levels for the chosen intervals. In this framework, an optimization algorithm (heuristic search method) was developed that gives the best possible partition of the predictions in contiguous intervals, i.e., maximizing the classification accuracies given a pre-defined number of intervals. The motivation for the development of this method was twofold: first, to provide a map user with the possibility to evaluate the map detail, i.e., number of intervals/classes, in dependence of the implied prediction accuracies; and second, to allow for identifying intervals of the response variable for which the map produces considerably high or low prediction accuracies. The applied procedures can also be downloaded as an \proglang{R} package from the GitHub development page \citep{github_classoptimr}.\par 

The suggested methods were applied in a mountainous study site in the canton of Grisons (Switzerland). Regional forest district inventory data were used in combination with data from an airborne laser scanning acquisition to produce a map of the standing timber volume on sample plot level. This map was subsequently evaluated by the developed accuracy assessment techniques. The setup of this study also addressed the overall question of the thesis, i.e., what prediction accuracies can be achieved on small spatial scales when using forest inventory data that are only available in comparatively low sampling frequencies.


%% NOTES
% - Mapping of forest attributes has always been of huge interest for forest practicioners.
% - Especially pixelwise (rasterized) maps of predicted forest attributes are considered to allow for spatially precise allocation of management operations such as harvesting etc.
% - Examples for integration of timber volume prediction maps are e.g. the optimal allocation of cable roads for harvesting in steep slope mountaineuous terrain demonstrated by Bont
% - The production of maps covering large areas has been substantially supported by the availablility of exhaustive remote sensing data.
% - Despite the advantages of providing high-resolution pixelated predictions maps, one should have in mind that the predictions are made for considerably small spatial units that often match the extent of a sample plot on which the prediction model has been calibrated. 
% - We thus consider (emphasize that) mapping as an extreme case of small area estimation where the small area basically constitutes the area of a sample plot.
% - Classical double-sampling estimators for small area estimation (such as used in chapter 3) provide closed-form variance formulas that allow for quantifying the estimation precision for every small area unit individually by its estimation error or confidence interval. 
% - These concepts of uncertainty estimation can however not be transferred to mapping approaches, particularly in the extreme case of a small area (i.e. map pixel) corresponding to the size of a sample plot. 
% - It thus appears necessary that similar efforts than for model building should be invested in providing methods to quantify the resulting map accuracies. 
% - A common way to characterize the map accuracy is to use the R$^2$ (coef. of determ.) and the cross-validated RMSE (root mean squared error), which rather address the overall prediction performance than the accuracy for individual predictions. As deriving confidence intervals on pixel level has been stated as an important contribution to map accuracies assessment, one possibility in the frame of linear regression is to use the prediction intervals (Source: Fahrmeier pp. xx - yy).
%
% - Compared to overall accuracy metrics such as RMSE, we consider that individual 'unit/pixel-level' CIs provide a more detailed and realistic idea of the map accuracies and should be preferred.
% - Thus, the objective of our study was to contribute to the range of methods available to provide confidence intervals for each individual pixel of a prediction map.
% -  We investigated an alternative approach of deriving pixelwise confidence intervals by applying well-known concepts of accuracy assessment for categorical classification results (Congalton and Green). The basic idea of our approach is to define intervals in the set of terrestrial data and their respective model predictions which subsequently allow for calculating the user's accuracy for each of these intervals. These intervals and their respective users' accuracies can thus be treated as confidence intervals. In this framework, we demonstrate a new heuristic search method that identifies those intervals with respect to the best possible classification accuracies given a pre-defined resolution of the predictions (i.e. number of classes).

% for discussion:
% - Compared to overall accuracy metrics such as RMSE, we consider that individual 'unit/pixel-level' CIs provide a more detailed and realistic idea of the map accuracies and should be preferred.
% - for discussion: with regard to an integration of sae methods in operation forest management information systems, its has to be considered which auxiliary data are available on a long-term perspective.

